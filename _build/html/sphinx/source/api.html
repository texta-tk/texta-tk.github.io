
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="et">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>API &#8212; Toolkit 1.3 dokumentatsioon</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/translations.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Indeks" href="../../genindex.html" />
    <link rel="search" title="Otsing" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="api">
<span id="id1"></span><h1>API<a class="headerlink" href="#api" title="Püsiviit sellele pealkirjale">¶</a></h1>
<p>TEXTA API can be used to query or process data without the need to interact with the graphical user interface.</p>
<p>It can be accessed from the address <em>&lt;texta_address&gt;/api</em></p>
<div class="section" id="authentication">
<h2>Authentication<a class="headerlink" href="#authentication" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>TEXTA API requires authentication in order to access any features. API authentication is handled by revokable authentication tokens. To make any API calls, one has to provide a valid authentication token, which is used to verify user permissions for different datasets.</p>
<div class="section" id="retrieving-the-token">
<h3>Retrieving the token<a class="headerlink" href="#retrieving-the-token" title="Püsiviit sellele pealkirjale">¶</a></h3>
<p>To retrieve an authorization token, one has to perform the following query:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl http://localhost:8000/account/get_auth_token -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;username&quot;: &quot;my_texta_username&quot;,</span>
<span class="s1">    &quot;password&quot;: &quot;my_texta_password&quot;</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>If authentication was successful, the authentication token is returned in the following format:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;auth_token&quot;</span><span class="p">:</span> <span class="s2">&quot;9c05321f821f6e&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p>The returned authentication token doesn’t expire and will be returned every time a token is requested by the user, until explicity revoked. If authentication token is likely to be compromised, it’s possible to revoke the token with the command</p>
<p>which returns</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;success&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="search">
<h2>Otsing<a class="headerlink" href="#search" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>Searching functionality allows to query documents based on the defined constraints and projections. Documents are queried and returned in JSON format.</p>
<div class="topic">
<p class="topic-title first">Example scenario</p>
<p>Let’s presume we have stored a variety of news articles with the following features: title, content, publish date, and author.</p>
<p>We can use TEXTA API to find all the articles by some fixed authors, articles which contain specific keywords or phrases, or articles which are published between two dates by selected authors and of which content contains keywords „president“ and „speech“, and not keywords „poverty“, „unhappiness“, and „falling behind“.</p>
</div>
<p>To download all the documents from the dataset with ID 4, it suffices to call</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/search&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>Retrieving all the documents isn’t necessarily the smartest thing to do. Next we might want to limit the number of documents we receive to 100 and get only the titles and the authors.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/search&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4,</span>
<span class="s1">    &quot;fields&quot;: [&quot;title&quot;, &quot;author&quot;],</span>
<span class="s1">    &quot;parameters&quot;: {&quot;limit&quot;: 100}</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>Although we now have some control over how we receive our data, we can’t still control what we receive. For that, we have to define constraints which the returned documents must satisfy. Let’s retrieve the title and the content of 15 articles published in 2017 by the renowned author John Doe.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/search&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4,</span>
<span class="s1">    &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;],</span>
<span class="s1">    &quot;parameters&quot;: {&quot;limit&quot;: 15},</span>
<span class="s1">    &quot;constraints&quot;: [</span>
<span class="s1">        {&quot;field&quot;:&quot;author&quot;,&quot;operator&quot;:&quot;must&quot;,&quot;type&quot;:&quot;match_phrase&quot;,&quot;slop&quot;:0,&quot;strings&quot;:[&quot;John Doe&quot;], &quot;class&quot;:&quot;string&quot;},</span>
<span class="s1">        {&quot;field&quot;:&quot;published&quot;, &quot;class&quot;:&quot;date&quot;, &quot;start&quot;:&quot;2017-01-01&quot;, &quot;end&quot;:&quot;2017-12-31&quot;}</span>
<span class="s1">    ]</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>The approach so far is streaming all the matching documents, meaning that the user will receive the data over a period of time with a single request. The returned documents have the following format:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;John Doe is the best&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;True story.&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;John Doe strikes again!&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;Image of a man assaulting tanks with a flower&gt;&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Johnny hit by a 50 ton tank&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Local hero John Doe stormed a tank on a military parade, but couldn&#39;t stop in time.&quot;</span><span class="p">}</span>
<span class="o">...</span>
</pre></div>
</div>
<p>Although streaming is great for downloading huge files, it can be inconvenient to download and process programmatically, which is why TEXTA API also allows to download one batch at a time using the scroll mechanism.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/search&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4,</span>
<span class="s1">    &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;],</span>
<span class="s1">    &quot;parameters&quot;: {&quot;size&quot;: 20},</span>
<span class="s1">    &quot;constraints&quot;: [</span>
<span class="s1">        {&quot;field&quot;:&quot;author&quot;,&quot;operator&quot;:&quot;must&quot;,&quot;type&quot;:&quot;match_phrase&quot;,&quot;slop&quot;:0,&quot;strings&quot;:[&quot;John Doe&quot;], &quot;class&quot;:&quot;string&quot;},</span>
<span class="s1">        {&quot;field&quot;:&quot;published&quot;, &quot;class&quot;:&quot;date&quot;, &quot;start&quot;:&quot;2017-01-01&quot;, &quot;end&quot;:&quot;2017-12-31&quot;}</span>
<span class="s1">    ],</span>
<span class="s1">    &quot;scroll&quot;: true</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>Here we set the „scroll“ flag to <em>True</em> and defined batch size in the parameters. Batch size defines how many documents will be returned in a single query. The result of the query looks like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;scroll_id&quot;</span><span class="p">:</span> <span class="s2">&quot;some very long hash string&quot;</span><span class="p">,</span>
    <span class="s2">&quot;total&quot;</span><span class="p">:</span> <span class="mi">1572</span><span class="p">,</span>
    <span class="s2">&quot;hits&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;John Doe is the best&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;True story.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;John Doe strikes again!&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;Image of a man assaulting tanks with a flower&gt;&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;Johnny hit by a 50 ton tank&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Local hero John Doe stormed a tank on a military parade, but couldn&#39;t stop in time.&quot;</span><span class="p">},</span>
        <span class="o">...</span> <span class="n">x</span> <span class="mi">17</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now, when we want to get the next batch of documents, it suffices to query</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/search&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4,</span>
<span class="s1">    &quot;scroll_id&quot;: &quot;that very long hash string we retrieved before&quot;</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>When all 1572 documents have been retrieved with the batches, the results look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;scroll_id&quot;</span><span class="p">:</span> <span class="s2">&quot;some very long hash string&quot;</span><span class="p">,</span>
    <span class="s2">&quot;total&quot;</span><span class="p">:</span> <span class="mi">1572</span><span class="p">,</span>
    <span class="s2">&quot;hits&quot;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="section" id="constraints">
<h3>Constraints<a class="headerlink" href="#constraints" title="Püsiviit sellele pealkirjale">¶</a></h3>
<p>Constraints are distinguished by classes.</p>
<div class="section" id="textual">
<h4>Textual<a class="headerlink" href="#textual" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Textual constraint’s class is <strong>string</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span><span class="s2">&quot;author&quot;</span><span class="p">,</span><span class="s2">&quot;operator&quot;</span><span class="p">:</span><span class="s2">&quot;must&quot;</span><span class="p">,</span><span class="s2">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;match_phrase&quot;</span><span class="p">,</span><span class="s2">&quot;slop&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;strings&quot;</span><span class="p">:[</span><span class="s2">&quot;John Doe&quot;</span><span class="p">],</span> <span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;string&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p><strong>field:</strong> name of the field/feature on which the constraint is applied.</p>
<p><strong>strings:</strong> keywords or phrases to search for.</p>
<p><strong>operator:</strong> relationship between the keyword.</p>
<blockquote>
<div><p><strong>„must“</strong> - <em>default</em> - conjunctive (AND) directive, all the listed keywords must exist in the document.</p>
<p><strong>„should“</strong> - disjunctive (OR) directive, at least one keyword must exist in the document.</p>
<p><strong>„must_not“</strong> - prohibitive (NOT) directive, none of the listed keywords can exist in the document.</p>
</div></blockquote>
<p><strong>type:</strong> defines how the keywords must match.</p>
<blockquote>
<div><p><strong>„match“</strong> - at least on token of whitespace split keywords must match, often used for single token keywords, like „John“.</p>
<p><strong>„match_phrase“</strong> - <em>default</em> - all the tokens of the keywords must match, can have „slop“ number of non-matching words in-between, matches also single tokens.</p>
<p><strong>„match_phrase_prefix“</strong> - listed keywords must be the preficies of the words actually in the document. Good for matching „look“ -&gt; „looking“</p>
</div></blockquote>
<p><strong>slop:</strong> defines how many other tokens/words can be between any phrase components. Slop 0 wouldn’t match „John Doe“ to „John Edward Doe“, slop 1 would.</p>
</div>
<div class="section" id="temporal">
<h4>Temporal<a class="headerlink" href="#temporal" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Temporal constraint’s class is <strong>date</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span><span class="s2">&quot;published&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="s2">&quot;start&quot;</span><span class="p">:</span><span class="s2">&quot;2017-01-01&quot;</span><span class="p">,</span> <span class="s2">&quot;end&quot;</span><span class="p">:</span><span class="s2">&quot;2017-12-31&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p><strong>start:</strong> start date.</p>
<p><strong>end:</strong> end date.</p>
</div>
<div class="section" id="simple-annotational">
<h4>Simple annotational<a class="headerlink" href="#simple-annotational" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Annotation data is on top of regular features and gives semantical meaning to parts of the feature (words, phrases, sentences, paragraphs). For example, if in our dataset we have articles about annual presidential speeches, we might want to annotate occurrences of „Vladimir Putin“, „Donald Trump“ or „Barack Obama“ with the keyword „president“, so that we could later on query the documents, which talk about presidents or presidential speeches, rather than individually list all the presidents that have ever been or will be in the query. Annotation is done via information extraction - either using TEXTA Grammar Miner or external tools.</p>
<p>Simple annotation’s constraint class is <strong>fact</strong>. The following constraint finds all the documents, for which there are phrases labelled as „president“ AND (beacause of must operator) „prime_minister“, meaning that it finds all articles which mention both heads of a state.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span><span class="s2">&quot;content&quot;</span><span class="p">,</span><span class="s2">&quot;operator&quot;</span><span class="p">:</span><span class="s2">&quot;must&quot;</span><span class="p">,</span><span class="s2">&quot;strings&quot;</span><span class="p">:[</span><span class="s2">&quot;president&quot;</span><span class="p">,</span> <span class="s2">&quot;prime_minister&quot;</span><span class="p">],</span> <span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;fact&quot;</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="advanced-annotational">
<h4>Advanced annotational<a class="headerlink" href="#advanced-annotational" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>„Advanced“ annotation queries include the value of the annotation. If simple annotation was only concerned about the fact, whether an article contained a reference to an arbitrary president or prime minister, then advanced annotation allows to query articles, which are about specific presidents. For example about president Donald Trump. The value also helps to differentiate between articles in which Donald Trump was in his presidential role, and articles, in which he wasn’t.</p>
<p>Advanced annotation’s constraint class is <strong>fact_val</strong>. The following constraint finds all the documents, in which Trump isn’t meddling with Russian interests.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;field&quot;</span><span class="p">:</span><span class="s2">&quot;content&quot;</span><span class="p">,</span>
    <span class="s2">&quot;operator&quot;</span><span class="p">:</span><span class="s2">&quot;must&quot;</span><span class="p">,</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;str&quot;</span><span class="p">,</span>
    <span class="s2">&quot;constraints&quot;</span><span class="p">:[</span>
           <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;president&quot;</span><span class="p">,</span><span class="s2">&quot;operator&quot;</span><span class="p">:</span><span class="s2">&quot;=&quot;</span><span class="p">,</span><span class="s2">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;Donald Trump&quot;</span><span class="p">},</span>
           <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;country&quot;</span><span class="p">,</span><span class="s2">&quot;operator&quot;</span><span class="p">:</span><span class="s2">&quot;!=&quot;</span><span class="p">,</span><span class="s2">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;Russian Federation&quot;</span><span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;fact_val&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>type:</strong> type of the fact value.</p>
<blockquote>
<div><p><strong>„str“</strong> - textual fact values.</p>
<p><strong>„num“</strong> - numerical fact values (numbers, dates, etc).</p>
</div></blockquote>
<p><strong>constraints:</strong> list of fact value constraints, which must match a document, in order for it to be returned.</p>
<blockquote>
<div><p>Fact value constraints have always <strong>„name“</strong>, <strong>„operator“</strong>, and <strong>„value“</strong> attributes.</p>
<p>„Operator“ and „value“ attribute values depend on „type“ value.</p>
<dl class="docutils">
<dt>If „type“ is „str“:</dt>
<dd>„operator“ can obtain values „=“ and „!=“;
„value“ is string and in quotes.</dd>
<dt>If „type“ is „num“:</dt>
<dd>„operator“ can obtain values „=“, „!=“, „&gt;“, „&gt;=“, „&lt;“, „&lt;=“;
„value“ is numeric for numbers, string in correct date format for dates.</dd>
</dl>
</div></blockquote>
</div>
</div>
</div>
<div class="section" id="aggregate">
<h2>Aggregate<a class="headerlink" href="#aggregate" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>Aggregation allows to calculate document distributions by grouping over specific feature values.</p>
<div class="topic">
<p class="topic-title first">Example scenario</p>
<p>Let’s presume we have stored a variety of news articles with the following features: title, content, publish date, and author.</p>
<p>With aggregation we can find out, how many articles were written each month, by aggregating over publish date with monthly interval. We can also find the top publishing authors each year or the most relevant keywords from articles mentioning prime minister candidate during an election period.</p>
</div>
<p>If we are interested in finding out, how many articles has each author writtern, we can query it as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/aggregate&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;searches&quot;: [{&quot;dataset&quot;: 4}],</span>
<span class="s1">    &quot;aggregation&quot;: [{&quot;field&quot;: &quot;author&quot;, &quot;type&quot;: &quot;string&quot;, &quot;sort_by&quot;: &quot;terms&quot;}]</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>As we can see, aggregation query depends on two attributes - „searches“ and „aggregation“. „Searches“ is a list of search definitions which we have already met in the previous section. Search defines the subset of the original data on which we run the aggregation. This time it’s used internally: we are not receiving and documents.</p>
<p>The possiblity to aggregate against several data subsets allows us to find interesting comparable statistics. For example, we can get the most eager authors on cars and dogs with the following query:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/aggregate&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;searches&quot;: [</span>
<span class="s1">        {</span>
<span class="s1">            &quot;dataset&quot;: 4,</span>
<span class="s1">            &quot;constraints&quot;: [{&quot;field&quot;:&quot;content&quot;,&quot;operator&quot;:&quot;must&quot;,&quot;type&quot;:&quot;match_phrase&quot;,&quot;slop&quot;:0,&quot;strings&quot;:[&quot;car&quot;], &quot;class&quot;:&quot;string&quot;}]</span>
<span class="s1">        },</span>
<span class="s1">        {</span>
<span class="s1">            &quot;dataset&quot;: 4,</span>
<span class="s1">            &quot;constraints&quot;: [{&quot;field&quot;:&quot;content&quot;,&quot;operator&quot;:&quot;must&quot;,&quot;type&quot;:&quot;match_phrase&quot;,&quot;slop&quot;:0,&quot;strings&quot;:[&quot;dog&quot;], &quot;class&quot;:&quot;string&quot;}]</span>
<span class="s1">        },</span>
<span class="s1">    ],</span>
<span class="s1">    &quot;aggregation&quot;: [{&quot;field&quot;: &quot;author&quot;, &quot;type&quot;: &quot;string&quot;, &quot;sort_by&quot;: &quot;terms&quot;}]</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>This returns us a list of two dictionaries - the first dictionary contains aggregation results for the first search, the second dictionary contains results for the second.</p>
<p>So far we have aggregated only over one level - author. However, imagine if we could aggregate over several. For example, what if we want to see the most active author on a monthly basis, without the necessity to explicitly create separate monthly date range searches for several years. Or what if we want to find the favourite words for different authors?</p>
<p>TEXTA API aggregation allows to aggregate over several levels.</p>
<p>To find out the most active authors on a monthly basis, we can execute the following query:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/api/aggregate&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;searches&quot;: [{&quot;dataset&quot;: 4}],</span>
<span class="s1">    &quot;aggregation&quot;: [</span>
<span class="s1">        {&quot;field&quot;:&quot;published&quot;,&quot;type&quot;:&quot;daterange&quot;,&quot;start&quot;:&quot;2010-02-02&quot;,&quot;end&quot;:&quot;2017-09-01&quot;,&quot;frequency&quot;:&quot;raw_frequency&quot;,&quot;interval&quot;:&quot;month&quot;}</span>
<span class="s1">        {&quot;field&quot;: &quot;author&quot;, &quot;type&quot;: &quot;string&quot;, &quot;sort_by&quot;: &quot;terms&quot;}</span>
<span class="s1">    ]</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>This returns us the number of documents written by specific authors per each month in the date range.</p>
<div class="section" id="aggregation-types">
<h3>Aggregation types<a class="headerlink" href="#aggregation-types" title="Püsiviit sellele pealkirjale">¶</a></h3>
<div class="section" id="id2">
<h4>Textual<a class="headerlink" href="#id2" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>The most common aggregation is over the existing text body and its type is „string“.</p>
<p>{„field“: „content“, „type“: „string“, „sort_by“: „significant_terms“}</p>
<p><strong>sort_by:</strong> defines, how the results will be scored and ordered.</p>
<blockquote>
<div><p><strong>„term“</strong> - order by raw document count. If „car“ is in more documents than „dog“, then „car“ takes precedence over „dog“.</p>
<p><strong>„significant_term“</strong> - order by the level of interest. Term is more interesting if it is more common in the observed data subset than in all the documents.</p>
</div></blockquote>
</div>
<div class="section" id="id3">
<h4>Temporal<a class="headerlink" href="#id3" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Temporal aggregation has type „daterange“.</p>
<p>{„field“:“published“,“type“:“daterange“,“start“:“2010-02-02“,“end“:“2017-09-01“,
„frequency“:“raw_frequency“,“interval“:“year“}</p>
<p><strong>frequency:</strong></p>
<p><strong>interval:</strong> length of the time periods into which the time from „start“ to „end“ is divided.</p>
<blockquote>
<div><strong>„day“</strong>, <strong>„week“</strong>, <strong>„month“</strong>, <strong>„quarter“</strong>, <strong>„year“</strong></div></blockquote>
</div>
<div class="section" id="id4">
<h4>Simple annotational<a class="headerlink" href="#id4" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Simple annotation aggregation has type „fact“.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fact&quot;</span><span class="p">,</span> <span class="s2">&quot;sort_by&quot;</span><span class="p">:</span> <span class="s2">&quot;terms&quot;</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h4>Advanced annotational<a class="headerlink" href="#id5" title="Püsiviit sellele pealkirjale">¶</a></h4>
<p>Advanced annotation aggregation has a type, which depends on the data type of the values.</p>
<p>If we are interested in textual annotations, we use the type „fact_str“.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fact_str&quot;</span><span class="p">,</span> <span class="s2">&quot;sort_by&quot;</span><span class="p">:</span> <span class="s2">&quot;terms&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p>If we are interested in numeric/temporal annotations, we use the type „fact_num“.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;field&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fact_num&quot;</span><span class="p">,</span> <span class="s2">&quot;sort_by&quot;</span><span class="p">:</span> <span class="s2">&quot;terms&quot;</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="list-datasets">
<h2>List datasets<a class="headerlink" href="#list-datasets" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>Listing datasets is important in order to construct queries on correct datasets.</p>
<p>To get the list of available and permitted datasets, we issue the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl http://localhost:8000/search_api/list/datasets -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>which returns</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="s2">&quot;journalA&quot;</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;mappping&quot;</span><span class="p">:</span> <span class="s2">&quot;articles&quot;</span><span class="p">,</span> <span class="s2">&quot;author&quot;</span><span class="p">:</span> <span class="s2">&quot;superadmin&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="s2">&quot;journalB&quot;</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;mappping&quot;</span><span class="p">:</span> <span class="s2">&quot;ancient_articles&quot;</span><span class="p">,</span> <span class="s2">&quot;author&quot;</span><span class="p">:</span> <span class="s2">&quot;superadmin&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="s2">&quot;joy_of_life&quot;</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;mappping&quot;</span><span class="p">:</span> <span class="s2">&quot;stories&quot;</span><span class="p">,</span> <span class="s2">&quot;author&quot;</span><span class="p">:</span> <span class="s2">&quot;mystery_admin&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p><strong>id:</strong> ID of the dataset, used in TEXTA API searches.</p>
<p><strong>index:</strong> database name.</p>
<p><strong>mapping:</strong> table name.</p>
<p><strong>author:</strong> username of the admin, who added the dataset.</p>
</div>
<div class="section" id="get-dataset-field-details">
<h2>Get dataset field details<a class="headerlink" href="#get-dataset-field-details" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>It is necessary to know the existing fields and their data types to construct accurate queries.</p>
<p>One can get detailed structure of the dataset with ID 4 with the following query:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl http://localhost:8000/search_api/list -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;dataset&quot;: 4</span>
<span class="s1">}&#39;</span>
</pre></div>
</div>
<p>The response is however rather complicated and often it makes more sense to use TEXTA graphical user interface’s Searcher tool to explore the dataset.</p>
</div>
<div class="section" id="importer-api">
<h2>Importer API<a class="headerlink" href="#importer-api" title="Püsiviit sellele pealkirjale">¶</a></h2>
<p>To insert data into Elasticsearch, a convenient API is provided for both single and bulk insertion at the <strong>/import_api/document_insertion</strong>
endpoint.
Each call to the Importer <strong>MUST</strong> have the following fields:</p>
<blockquote>
<div><p><strong>auth_token</strong> - Authentication token provided from the Authentication API</p>
<p><strong>index</strong> - Name of the target index you want to push the data to. In case one doesn’t exist, it will be created.</p>
<p><strong>doc_type</strong> - Target „table“ you want to push your data into.</p>
<p><strong>data</strong> - List of JSON object or a single object. In case of a list, the Bulk API will be used for insertion.</p>
</div></blockquote>
<p>Optionally you can also specify a <strong>mapping</strong> field, in case the index of the specified name does not exist and is created,
a check for the <strong>mapping</strong> field is made, and if it exists it is inserted into the target doc_type.</p>
<p>In case an invalid authentication token is provided or a mandatory field is missing a corresponding error message will be returned
to the end user.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/import_api/document_insertion&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;index&quot;: &quot;texta&quot;,</span>
<span class="s1">    &quot;doc_type&quot;: &quot;texta_facts&quot;,</span>
<span class="s1">    &quot;data&quot;: {&quot;court_case_6543&quot;: &quot;guilty&quot;}</span>
<span class="s1">}&#39;</span>

<span class="c1"># {&quot;message&quot;: &quot;Item(s) successfully saved.&quot;}</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/import_api/document_insertion&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;index&quot;: &quot;texta&quot;,</span>
<span class="s1">    &quot;doc_type&quot;: &quot;texta_facts&quot;,</span>
<span class="s1">    &quot;data&quot;: [{&quot;court_case_6543&quot;: &quot;guilty&quot;}, {&quot;court_case_9614&quot;: &quot;fined&quot;}, {&quot;court_case_7896&quot;: &quot;innocent&quot;}]</span>
<span class="s1">}&#39;</span>

<span class="c1"># {&quot;message&quot;: &quot;Item(s) successfully saved.&quot;}</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/import_api/document_insertion&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f8&quot;,</span>
<span class="s1">    &quot;index&quot;: &quot;texta&quot;,</span>
<span class="s1">    &quot;doc_type&quot;: &quot;texta_facts&quot;,</span>
<span class="s1">    &quot;data&quot;: {&quot;court_case_6543&quot;: &quot;guilty&quot;}</span>
<span class="s1">}&#39;</span>

<span class="c1"># {&quot;message&quot;: &quot;Authentication failed - invalid auth token.&quot;}</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/import_api/document_insertion&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>
<span class="s1">    &quot;index&quot;: &quot;&quot;,</span>
<span class="s1">    &quot;doc_type&quot;: &quot;texta_facts&quot;,</span>
<span class="s1">    &quot;data&quot;: [{&quot;court_case_6543&quot;: &quot;guilty&quot;}, {&quot;court_case_9614&quot;: &quot;fined&quot;}, {&quot;court_case_7896&quot;: &quot;innocent&quot;}]</span>
<span class="s1">}&#39;</span>

<span class="c1"># {&quot;message&quot;: &quot;Mandatory field &#39;index&#39; can not be empty.&quot;}</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ curl -XPOST <span class="s1">&#39;http://localhost:8000/import_api/document_insertion&#39;</span> -d <span class="s1">&#39;{</span>
<span class="s1">    &quot;auth_token&quot;: &quot;9c05321f821f6e&quot;,</span>

<span class="s1">    &quot;doc_type&quot;: &quot;texta_facts&quot;,</span>
<span class="s1">    &quot;data&quot;: [{&quot;court_case_6543&quot;: &quot;guilty&quot;}, {&quot;court_case_9614&quot;: &quot;fined&quot;}, {&quot;court_case_7896&quot;: &quot;innocent&quot;}]</span>
<span class="s1">}&#39;</span>

<span class="c1"># {&quot;message&quot;: &quot;Mandatory field &#39;index&#39; is missing.&quot;}</span>
</pre></div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Toolkit</a></h1>








<h3>Navigatsioon</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Kiirotsing</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Otsi" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Silver Traat.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.0+/7e143a0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/sphinx/source/api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>